{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "T5_Transformer_FineTuning.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "114a7d686e2740a3911a18724bf5c0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b63a861213a4115bcaf7e1d07455d46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31d7be21ea634971820ab5f021071b39",
              "IPY_MODEL_1eda7bb7ce8b445b94bb7c42b36f4c53"
            ]
          }
        },
        "3b63a861213a4115bcaf7e1d07455d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31d7be21ea634971820ab5f021071b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bcddaaea9a50433c8bf809479bed1bee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_814101bca88044bbb2d809ed6f80e093"
          }
        },
        "1eda7bb7ce8b445b94bb7c42b36f4c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0364dd2e9b8e4a4e93407ffb36a66fe3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:03&lt;00:00, 250kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d982a7918a64a32afcf3ce67ee54c1c"
          }
        },
        "bcddaaea9a50433c8bf809479bed1bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "814101bca88044bbb2d809ed6f80e093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0364dd2e9b8e4a4e93407ffb36a66fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d982a7918a64a32afcf3ce67ee54c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41a9d158130d4db0b5a972edfd42d34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab4f1a3403ba4329bc3f29cf79124334",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_397e1d6255514e68b9a4448df46e9288",
              "IPY_MODEL_9cc3025524db43eb86a25f0587af2313"
            ]
          }
        },
        "ab4f1a3403ba4329bc3f29cf79124334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "397e1d6255514e68b9a4448df46e9288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3d730fe2a6f74ec9a8d4c2298a9a06a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_658f60d7ec9b4c26ab58fec82117a21e"
          }
        },
        "9cc3025524db43eb86a25f0587af2313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2ce51cb2d584f3daa9533be7ba4500e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 2.87kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b96616eada8948f987b623e3be153f59"
          }
        },
        "3d730fe2a6f74ec9a8d4c2298a9a06a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "658f60d7ec9b4c26ab58fec82117a21e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2ce51cb2d584f3daa9533be7ba4500e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b96616eada8948f987b623e3be153f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2811e2d4859d4629a95da795a3fd7baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3bcfb6e5b3fa4521971421a6e14e9bfd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_064d0407aa35425ba3bdd16f84709dc9",
              "IPY_MODEL_5d24ef4997184cfe8ab24b32a449abc0"
            ]
          }
        },
        "3bcfb6e5b3fa4521971421a6e14e9bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "064d0407aa35425ba3bdd16f84709dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb9773879bb24017ab0fb5d0c3c731c6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242065649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242065649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43acd48f88a743f48b1738a107a509dc"
          }
        },
        "5d24ef4997184cfe8ab24b32a449abc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_533c595362dd49a0b98f6ead3eefd7dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:03&lt;00:00, 72.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01c62f4afa9a47c3a3e3c7e42cb32109"
          }
        },
        "cb9773879bb24017ab0fb5d0c3c731c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43acd48f88a743f48b1738a107a509dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "533c595362dd49a0b98f6ead3eefd7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01c62f4afa9a47c3a3e3c7e42cb32109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uZ5NAnc9g3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c21d639a-f1c6-462b-9298-8b95c408619d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Sep 24 11:30:45 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Q90sP6CeRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "ef0e1f29-b599-4d3d-8dfb-dd9f6589abe9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 20.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=53fbbe9d9820cd96944cd13c6579df2ad0f13990a408116e1134f6e0b60a4e0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ns2ZPl2ByW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6de942c0-9504-4f9e-e077-4d6b305f079b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccqFe9R69cvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTL2BAPte78y",
        "colab_type": "text"
      },
      "source": [
        "## Read Data from Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S06yA-YOe8Hj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOsgJllzCCgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Files/stories_with_summary_train_cleaned.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LgoOXoVfCsC",
        "colab_type": "text"
      },
      "source": [
        "## Check for GPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2fT_CnU9cvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53fccfba-03dc-4d65-c1fe-cd8a764c6cb4"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "SHUFFLE_SIZE = 1024\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 1e-4\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdG2zEw8fGH-",
        "colab_type": "text"
      },
      "source": [
        "## Load T5 Transformer model for fine tuning from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUmKcKsF9cvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "114a7d686e2740a3911a18724bf5c0c6",
            "3b63a861213a4115bcaf7e1d07455d46",
            "31d7be21ea634971820ab5f021071b39",
            "1eda7bb7ce8b445b94bb7c42b36f4c53",
            "bcddaaea9a50433c8bf809479bed1bee",
            "814101bca88044bbb2d809ed6f80e093",
            "0364dd2e9b8e4a4e93407ffb36a66fe3",
            "3d982a7918a64a32afcf3ce67ee54c1c",
            "41a9d158130d4db0b5a972edfd42d34f",
            "ab4f1a3403ba4329bc3f29cf79124334",
            "397e1d6255514e68b9a4448df46e9288",
            "9cc3025524db43eb86a25f0587af2313",
            "3d730fe2a6f74ec9a8d4c2298a9a06a4",
            "658f60d7ec9b4c26ab58fec82117a21e",
            "c2ce51cb2d584f3daa9533be7ba4500e",
            "b96616eada8948f987b623e3be153f59",
            "2811e2d4859d4629a95da795a3fd7baa",
            "3bcfb6e5b3fa4521971421a6e14e9bfd",
            "064d0407aa35425ba3bdd16f84709dc9",
            "5d24ef4997184cfe8ab24b32a449abc0",
            "cb9773879bb24017ab0fb5d0c3c731c6",
            "43acd48f88a743f48b1738a107a509dc",
            "533c595362dd49a0b98f6ead3eefd7dd",
            "01c62f4afa9a47c3a3e3c7e42cb32109"
          ]
        },
        "outputId": "f7bc203b-ec95-4018-beac-eb09fa821c9f"
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
        "\n",
        "task_specific_params = model.config.task_specific_params\n",
        "if task_specific_params is not None:\n",
        "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
        "    \n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=0.0001)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "114a7d686e2740a3911a18724bf5c0c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41a9d158130d4db0b5a972edfd42d34f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1197.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2811e2d4859d4629a95da795a3fd7baa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242065649.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVyCw6HeCoqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8dcc72bc-b35a-4439-f56a-efc81bbfc709"
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>cleaned_stories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
              "      <td>['Syrian official: Obama climbed to the top of...</td>\n",
              "      <td>it is official u.s. president barack obama wan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             article  ...                                    cleaned_stories\n",
              "0  It's official: U.S. President Barack Obama wan...  ...  it is official u.s. president barack obama wan...\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQzpgltfOHh",
        "colab_type": "text"
      },
      "source": [
        "## Create Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVFdbnTf9cvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SummaryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, articles, highlights):\n",
        "        self.x = articles\n",
        "        self.y = highlights\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = tokenizer.encode_plus(model.config.prefix + self.x[index], max_length=512,truncation=True ,return_tensors=\"pt\", pad_to_max_length=True)\n",
        "        y = tokenizer.encode(self.y[index], max_length=150, truncation=True,return_tensors=\"pt\", pad_to_max_length=True)\n",
        "        return x['input_ids'].view(-1), x['attention_mask'].view(-1), y.view(-1)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMKb3CJxCc4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdjhd-J29cvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train,df_test = train_test_split(df,test_size = 0.1)\n",
        "df_val ,df_test = train_test_split(df_test,test_size =0.5)\n",
        "\n",
        "train_dataset = SummaryDataset(articles = df_train.cleaned_stories.values, highlights = df_train.summary.values)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
        "\n",
        "val_dataset = SummaryDataset(articles = df_val.cleaned_stories.values, highlights = df_val.summary.values)\n",
        "val_data_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = SummaryDataset(articles = df_test.cleaned_stories.values, highlights = df_test.summary.values)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkOcLq4p9cvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_token_id = tokenizer.pad_token_id\n",
        "def step(inputs_ids, attention_mask, y):\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    lm_labels = y[:, 1:].clone()\n",
        "    lm_labels[y[:, 1:] == pad_token_id] = -100\n",
        "    output = model(inputs_ids, attention_mask=attention_mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
        "    return output[0] # loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGe7_90JfVMO",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tuning / Training T5 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlNvxQ_M9cv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "e760169a-a9a1-4927-e40b-52d035c82f3e"
      },
      "source": [
        "EPOCHS = 2\n",
        "log_interval = 200\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train() \n",
        "    start_time = time.time()\n",
        "    for i, (inputs_ids, attention_mask, y) in enumerate(train_data_loader):\n",
        "        inputs_ids = inputs_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = step(inputs_ids, attention_mask, y)\n",
        "        train_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "            \n",
        "        if (i + 1) % log_interval == 0:\n",
        "            with torch.no_grad():\n",
        "                x, x_mask, y = next(iter(val_data_loader))\n",
        "                x = x.to(device)\n",
        "                x_mask = x_mask.to(device)\n",
        "                y = y.to(device)\n",
        "                \n",
        "                v_loss = step(x, x_mask, y)\n",
        "                v_loss = v_loss.item()\n",
        "                \n",
        "                \n",
        "                elapsed = time.time() - start_time\n",
        "                print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
        "                  'ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
        "                    epoch+1, i, len(train_data_loader),\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    loss.item(), v_loss))\n",
        "                start_time = time.time()\n",
        "                val_loss.append(v_loss)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 | [  199/ 5207] | ms/batch 488.12 | loss  2.65 | val loss  2.81\n",
            "| epoch   1 | [  399/ 5207] | ms/batch 486.10 | loss  2.24 | val loss  2.63\n",
            "| epoch   1 | [  599/ 5207] | ms/batch 487.06 | loss  2.42 | val loss  2.49\n",
            "| epoch   1 | [  799/ 5207] | ms/batch 486.50 | loss  2.20 | val loss  2.52\n",
            "| epoch   1 | [  999/ 5207] | ms/batch 486.41 | loss  2.36 | val loss  2.48\n",
            "| epoch   1 | [ 1199/ 5207] | ms/batch 487.33 | loss  2.38 | val loss  2.47\n",
            "| epoch   1 | [ 1399/ 5207] | ms/batch 486.71 | loss  2.26 | val loss  2.45\n",
            "| epoch   1 | [ 1599/ 5207] | ms/batch 486.44 | loss  2.34 | val loss  2.53\n",
            "| epoch   1 | [ 1799/ 5207] | ms/batch 486.69 | loss  2.33 | val loss  2.47\n",
            "| epoch   1 | [ 1999/ 5207] | ms/batch 487.36 | loss  1.99 | val loss  2.49\n",
            "| epoch   1 | [ 2199/ 5207] | ms/batch 486.96 | loss  2.34 | val loss  2.51\n",
            "| epoch   1 | [ 2399/ 5207] | ms/batch 486.67 | loss  2.54 | val loss  2.52\n",
            "| epoch   1 | [ 2599/ 5207] | ms/batch 488.49 | loss  2.39 | val loss  2.55\n",
            "| epoch   1 | [ 2799/ 5207] | ms/batch 488.49 | loss  2.36 | val loss  2.55\n",
            "| epoch   1 | [ 2999/ 5207] | ms/batch 485.55 | loss  2.62 | val loss  2.57\n",
            "| epoch   1 | [ 3199/ 5207] | ms/batch 485.32 | loss  2.60 | val loss  2.54\n",
            "| epoch   1 | [ 3399/ 5207] | ms/batch 484.81 | loss  2.42 | val loss  2.60\n",
            "| epoch   1 | [ 3599/ 5207] | ms/batch 486.49 | loss  2.31 | val loss  2.62\n",
            "| epoch   1 | [ 3799/ 5207] | ms/batch 483.96 | loss  1.97 | val loss  2.60\n",
            "| epoch   1 | [ 3999/ 5207] | ms/batch 486.12 | loss  2.45 | val loss  2.64\n",
            "| epoch   1 | [ 4199/ 5207] | ms/batch 485.61 | loss  2.26 | val loss  2.70\n",
            "| epoch   1 | [ 4399/ 5207] | ms/batch 486.20 | loss  2.28 | val loss  2.66\n",
            "| epoch   1 | [ 4599/ 5207] | ms/batch 486.99 | loss  2.91 | val loss  2.70\n",
            "| epoch   1 | [ 4799/ 5207] | ms/batch 486.50 | loss  2.44 | val loss  2.71\n",
            "| epoch   1 | [ 4999/ 5207] | ms/batch 487.09 | loss  2.75 | val loss  2.75\n",
            "| epoch   1 | [ 5199/ 5207] | ms/batch 485.91 | loss  2.67 | val loss  2.79\n",
            "| epoch   2 | [  199/ 5207] | ms/batch 486.00 | loss  2.65 | val loss  2.74\n",
            "| epoch   2 | [  399/ 5207] | ms/batch 485.21 | loss  2.38 | val loss  2.84\n",
            "| epoch   2 | [  599/ 5207] | ms/batch 486.88 | loss  2.68 | val loss  2.88\n",
            "| epoch   2 | [  799/ 5207] | ms/batch 486.29 | loss  2.54 | val loss  2.91\n",
            "| epoch   2 | [  999/ 5207] | ms/batch 484.78 | loss  2.69 | val loss  2.91\n",
            "| epoch   2 | [ 1199/ 5207] | ms/batch 485.51 | loss  2.73 | val loss  2.90\n",
            "| epoch   2 | [ 1399/ 5207] | ms/batch 484.46 | loss  2.68 | val loss  2.95\n",
            "| epoch   2 | [ 1599/ 5207] | ms/batch 484.09 | loss  2.86 | val loss  2.90\n",
            "| epoch   2 | [ 1799/ 5207] | ms/batch 484.95 | loss  2.76 | val loss  3.02\n",
            "| epoch   2 | [ 1999/ 5207] | ms/batch 486.36 | loss  2.46 | val loss  3.00\n",
            "| epoch   2 | [ 2199/ 5207] | ms/batch 485.24 | loss  2.88 | val loss  3.03\n",
            "| epoch   2 | [ 2399/ 5207] | ms/batch 485.34 | loss  2.97 | val loss  3.01\n",
            "| epoch   2 | [ 2599/ 5207] | ms/batch 486.01 | loss  2.88 | val loss  3.02\n",
            "| epoch   2 | [ 2799/ 5207] | ms/batch 486.47 | loss  2.89 | val loss  3.04\n",
            "| epoch   2 | [ 2999/ 5207] | ms/batch 485.88 | loss  3.10 | val loss  3.11\n",
            "| epoch   2 | [ 3199/ 5207] | ms/batch 485.77 | loss  3.01 | val loss  3.13\n",
            "| epoch   2 | [ 3399/ 5207] | ms/batch 484.84 | loss  2.86 | val loss  3.12\n",
            "| epoch   2 | [ 3599/ 5207] | ms/batch 486.59 | loss  2.88 | val loss  3.14\n",
            "| epoch   2 | [ 3799/ 5207] | ms/batch 484.57 | loss  2.54 | val loss  3.11\n",
            "| epoch   2 | [ 3999/ 5207] | ms/batch 486.77 | loss  2.93 | val loss  3.15\n",
            "| epoch   2 | [ 4199/ 5207] | ms/batch 487.48 | loss  2.70 | val loss  3.20\n",
            "| epoch   2 | [ 4399/ 5207] | ms/batch 485.29 | loss  2.75 | val loss  3.14\n",
            "| epoch   2 | [ 4599/ 5207] | ms/batch 486.09 | loss  3.45 | val loss  3.20\n",
            "| epoch   2 | [ 4799/ 5207] | ms/batch 486.59 | loss  2.92 | val loss  3.19\n",
            "| epoch   2 | [ 4999/ 5207] | ms/batch 485.34 | loss  3.22 | val loss  3.22\n",
            "| epoch   2 | [ 5199/ 5207] | ms/batch 484.70 | loss  3.13 | val loss  3.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwiB15oURX6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e8b1e93b-46c1-4a00-b560-687a8e01e86c"
      },
      "source": [
        "pip install rouge-score"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.18.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.15.0)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSvRslU2fbrg",
        "colab_type": "text"
      },
      "source": [
        "## Check Rouge Scores for Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lsfHcG9cv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from rouge_score import scoring\n",
        "\n",
        "class RougeScore:\n",
        "    '''\n",
        "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
        "    '''\n",
        "    \n",
        "    def __init__(self, score_keys=None)-> None:\n",
        "        super().__init__()\n",
        "        if score_keys is None:  \n",
        "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
        "        \n",
        "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
        "        self.aggregator = scoring.BootstrapAggregator()\n",
        "        \n",
        "        \n",
        "    @staticmethod\n",
        "    def prepare_summary(summary):\n",
        "            # Make sure the summary is not bytes-type\n",
        "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
        "            summary = summary.replace(\" . \", \" .\\n\")\n",
        "            return summary\n",
        "    \n",
        "    def __call__(self, target, prediction):\n",
        "        \"\"\"Computes rouge score.''\n",
        "        Args:\n",
        "        targets: string\n",
        "        predictions: string\n",
        "        \"\"\"\n",
        "\n",
        "        target = self.prepare_summary(target)\n",
        "        prediction = self.prepare_summary(prediction)\n",
        "        \n",
        "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
        "\n",
        "        return \n",
        "    \n",
        "    def reset_states(self):\n",
        "        self.rouge_list = []\n",
        "\n",
        "    def result(self):\n",
        "        result = self.aggregator.aggregate()\n",
        "        \n",
        "        for key in self.score_keys:\n",
        "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
        "                key,\n",
        "                result[key].mid.fmeasure*100,\n",
        "                result[key].low.fmeasure*100,\n",
        "                result[key].high.fmeasure*100\n",
        "            )\n",
        "            print(score_text)\n",
        "        \n",
        "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ULEBjs9cv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "30240332-703f-47a4-caf8-03a924ccad4a"
      },
      "source": [
        "rouge_score = RougeScore()\n",
        "predictions = []\n",
        "for i, (input_ids, attention_mask, y) in enumerate(test_data_loader):\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    y = y.to(device)\n",
        "        \n",
        "    summaries = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
        "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
        "    for pred_sent, real_sent in zip(pred, real):\n",
        "        rouge_score(pred_sent, real_sent)\n",
        "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
        "    if i > 40:\n",
        "        break\n",
        "    \n",
        "rouge_score.result()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rouge1 = 28.06, 95% confidence [27.37, 28.76]\n",
            "rouge2 = 8.18, 95% confidence [7.65, 8.75]\n",
            "rougeLsum = 18.41, 95% confidence [17.88, 19.00]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 28.056943591224226,\n",
              " 'rouge2': 8.181835123056894,\n",
              " 'rougeLsum': 18.405928023838808}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUAsY7lbffoS",
        "colab_type": "text"
      },
      "source": [
        "## Get some Sample Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NkoWnzW9cv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "90a9264e-9602-409a-9123-cbb65d796d26"
      },
      "source": [
        "for pred in predictions[:10]:\n",
        "    print(\"------\")\n",
        "    print(pred)\n",
        "    print(\"------\")  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------\n",
            "pred sentence: 'States Gallo fired all the teachers at Central Falls high school after years', 'President Obama got involved and supported the firing, saying if a teacher is responsible', \"He says teachers are failing to follow the curriculum's failure, he says\", 'He says he's not the answer because the teachers don't want to do a bad job']\n",
            "\n",
            " real sentence: ['Rhode Island school district fired teachers at a failing school', \"Teacher Esther Wojcicki says that's not the answer to poorly performing schools\", 'She says parents, administrators need to share blame, help solve problem', '\"No teacher can effectively educate a child without support from the parents,\" she says']\n",
            "------\n",
            "------\n",
            "pred sentence: ', 'A listers are now scratching at casting directors doors in their eagerness to voice voice', \"The movie's a roll call of big name actors has followed from tom Hanks as Woody's wiseccs\", 'The movie has become a big advantage']\n",
            "\n",
            " real sentence: ['From Johnny Depp to Angelina Jolie, A-list stars line up to voice animated movies', 'Robin Williams's performance as the genie in \"Aladdin\" removed stigma of voice work', 'Traditional voice artists rely on their versatility to survive']\n",
            "------\n",
            "------\n",
            "pred sentence: 'Mamkhawaja was born in Islamabad but moved to Australia', 'Kawja was named in a strong 14-man side for the series which begins on September 13', \"Analy a fully qualified pilot pilot, who was selected in Australia's cricket squad's squad\", 'Man Man Man Man Khawaja is the first muslim to play in the first-class cricket squad and could play in Pakistan']\n",
            "\n",
            " real sentence: ['Pakistan-born Usman Khawaja the first Muslim to be selected in an Australian Test squad', 'The 23-year-old Khawaja may play against his country of birth in series in Britain', 'Khawaja, a fully-qualified pilot, was born in Islamabad but moved to Australia when young', 'The two-Test series was moved to England due to safety concerns in Pakistan']\n",
            "------\n",
            "------\n",
            "pred sentence: 's gifs sequences of looping motions', 'Attass of gastis: \"I's work it almost transcends the Gif medium medium\"', \"The work of other artists are now gaining success in the world's new York City\", 'The ggif of a new york city city window cleaner, aims to create a painting']\n",
            "\n",
            " real sentence: ['Saatchi Gallery has teamed up with Google plus for the first GIF art award', 'The Motion Photography Prize went to Brooklyn artist Christina Rinaldi', 'Artists are increasingly looking to GIFs as bona-fide channels for self-expression']\n",
            "------\n",
            "------\n",
            "pred sentence: '\"Jackson's elderly mother will soon tell jurors about the singer's drug dependency\", 'The top producer of Michael Jackson was convicted of involuntary Manslaughter involol', 'Joos heard one of Gibson Gibson, 83, has sat on the front row of the 46 days of testimony']\n",
            "\n",
            " real sentence: [\"Katherine Jackson's testimony will be followed by defense from AEG Live lawyers\", 'CNN obtained video clips from the deposition of a former Jackson tour doctor', '\"I think we're going to have a problem,\" Dr. Stuart Finkelstein said he told Paul Gongaware', \"AEG Live exec Gongaware denied Finkelstein told him about Jackson's drug use\"]\n",
            "------\n",
            "------\n",
            "pred sentence: ', 'A woman watching the Dakar rally in Argentina died Saturday Saturday at a hospital in Cordoba', \"The event's web site says he's helped police and medical teams take care of the victims\", 'The race is in South America for the first time, organizers say']\n",
            "\n",
            " real sentence: ['Sonia Natalia Gallardo dies at a hospital in Cordoba, race organizers say', 'The incident involved German driver Mirco Schultis and Czech partner Ulrich Leardi', 'Spectator was standing \"outside a safety zone,\" photojournalist says']\n",
            "------\n",
            "------\n",
            "pred sentence: ', 'Sri Lanka Lanka Lankas will bow out of the five-day game on home soil soil', the ranked Sri Lanka', \"Two wickets will be available for limited over the West indies\", 'More than 84 more wickets in tests than his closest rival Sri Sri Lanka Lanka']\n",
            "\n",
            " real sentence: ['Spin bowler Muttiah Muralitharan has confirmed that he will retire from Test cricket', 'Sri Lanka Cricket released a statement about the 38-year-old record-holder on Tuesday', 'Muralitharan has taken 792 wickets in 132 Tests and 515 wickets in 337 one-day internationals', 'He will still be available for selection for the 2011 World Cup co-hosted by Sri Lanka']\n",
            "------\n",
            "------\n",
            "pred sentence: ', 'Yulia Tymoshenko refuses to concede a recount in some districts', \"Ty Moshenko has 48.98 percent of the votes count counted\", 'Ukrakrainian prime minister says he won a victory']\n",
            "\n",
            " real sentence: [\"Tymoshenko refuses to concede defeat in Ukraine's presidential election\", 'Former PM Victor Yanukovich tells CNN it is time for her to give up', 'With 98 percent of ballots processed, Yanukovich had 48.94 percent', 'Current Ukraine PM Yulia Tymoshenko has 45.48 percent']\n",
            "------\n",
            "------\n",
            "pred sentence: '\"Seoul Jong Un appears to carry his first public inspection with the country's military first policy\", 'He is accompanied by his uncle Taek, the senior senior senior official says', 'KKcna says he will carry on his father, and the military', \"KcNa says the military should be ready for actions\"\"]\n",
            "\n",
            " real sentence: ['The new North Korean leader carries out his first public inspection of the military', \"State-run media publish the annual New Year's message\", 'Kim Jong Un, who succeeded his father, deserves \"absolute trust,\" editorial says', 'It says 2012 will usher prosperity']\n",
            "------\n",
            "------\n",
            "pred sentence: 'NEW: A new call of Duty Duty Duty series will be released this year', 'Activision will begin briefing briefing reporters in San Francisco', \"Another investment will be provided free of charge to all of our customers\", 'The company will release a new new game in the next three months of downtime']\n",
            "\n",
            " real sentence: ['Activision Blizzard plans to release a new \"Call of Duty\" game this year', \"It will include a new social-network platform that's been in the works for two years\", '\"Call of Duty\" is one of Activision's two \"significant investments\"']\n",
            "------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "korIifcIflNd",
        "colab_type": "text"
      },
      "source": [
        "## Save Model State "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnc5lJ1x9cwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/Colab Files/t5_summarization_model_2_Epochs.pt')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I9FWHwmRbBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}