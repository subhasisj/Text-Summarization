{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SHUFFEL_SIZE = 1024\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 3e-5\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "\n",
    "task_specific_params = model.config.task_specific_params\n",
    "if task_specific_params is not None:\n",
    "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, articles, highlights):\n",
    "        self.x = articles\n",
    "        self.y = highlights\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = tokenizer.encode_plus(model.config.prefix + self.x[index], max_length=512, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "        y = tokenizer.encode(self.y[index], max_length=150, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "        return x['input_ids'].view(-1), x['attention_mask'].view(-1), y.view(-1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,test_size = 0.1)\n",
    "df_val ,df_test = train_test_split(df_test,test_size =0.5)\n",
    "\n",
    "train_dataset = SummaryDataset(articles = df_train.cleaned_stories.values, highlights = df_train.summary.values)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = SummaryDataset(articles = df_val.review.values, highlights = df_val.summary.values)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = SummaryDataset(articles = df_test.review.values, highlights = df_test.summary.values)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = tokenizer.pad_token_id\n",
    "def step(inputs_ids, attention_mask, y):\n",
    "    y_ids = y[:, :-1].contiguous()\n",
    "    lm_labels = y[:, 1:].clone()\n",
    "    lm_labels[y[:, 1:] == pad_token_id] = -100\n",
    "    output = model(inputs_ids, attention_mask=attention_mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "    return output[0] # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "log_interval = 200\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() \n",
    "    start_time = time.time()\n",
    "    for i, (inputs_ids, attention_mask, y) in enumerate(train_loader):\n",
    "        inputs_ids = inputs_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = step(inputs_ids, attention_mask, y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i + 1) % log_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                x, x_mask, y = next(iter(val_loader))\n",
    "                x = x.to(device)\n",
    "                x_mask = x_mask.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                v_loss = step(x, x_mask, y)\n",
    "                v_loss = v_loss.item()\n",
    "                \n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
    "                    epoch, i, len(train_loader),\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    loss.item(), v_loss))\n",
    "                start_time = time.time()\n",
    "                val_loss.append(v_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring\n",
    "\n",
    "class RougeScore:\n",
    "    '''\n",
    "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, score_keys=None)-> None:\n",
    "        super().__init__()\n",
    "        if score_keys is None:  \n",
    "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "        \n",
    "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
    "        self.aggregator = scoring.BootstrapAggregator()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def prepare_summary(summary):\n",
    "            # Make sure the summary is not bytes-type\n",
    "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
    "            summary = summary.replace(\" . \", \" .\\n\")\n",
    "            return summary\n",
    "    \n",
    "    def __call__(self, target, prediction):\n",
    "        \"\"\"Computes rouge score.''\n",
    "        Args:\n",
    "        targets: string\n",
    "        predictions: string\n",
    "        \"\"\"\n",
    "\n",
    "        target = self.prepare_summary(target)\n",
    "        prediction = self.prepare_summary(prediction)\n",
    "        \n",
    "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
    "\n",
    "        return \n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.rouge_list = []\n",
    "\n",
    "    def result(self):\n",
    "        result = self.aggregator.aggregate()\n",
    "        \n",
    "        for key in self.score_keys:\n",
    "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
    "                key,\n",
    "                result[key].mid.fmeasure*100,\n",
    "                result[key].low.fmeasure*100,\n",
    "                result[key].high.fmeasure*100\n",
    "            )\n",
    "            print(score_text)\n",
    "        \n",
    "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score = RougeScore()\n",
    "predictions = []\n",
    "for i, (input_ids, attention_mask, y) in enumerate(test_loader):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    y = y.to(device)\n",
    "        \n",
    "    summaries = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
    "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
    "    for pred_sent, real_sent in zip(pred, real):\n",
    "        rouge_score(pred_sent, real_sent)\n",
    "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
    "    if i > 40:\n",
    "        break\n",
    "    \n",
    "rouge_score.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in predictions[:10]:\n",
    "    print(\"------\")\n",
    "    print(pred)\n",
    "    print(\"------\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('t5model.h5')"
   ]
  }
 ]
}