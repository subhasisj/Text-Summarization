{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "T5_Transformer_FineTuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uZ5NAnc9g3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1809d3f7-fb07-4e2e-b53f-abde02fb5106"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 23 17:48:21 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    31W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Q90sP6CeRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "4ce4ce8e-d4bb-447c-a95c-f39dbf3fcda2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ns2ZPl2ByW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91911208-89ec-4e77-949f-77f877e790b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccqFe9R69cvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOsgJllzCCgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Files/stories_with_summary_train_cleaned.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2fT_CnU9cvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9582cceb-7eb1-4696-cabe-7dbf0c3c8b4a"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "SHUFFLE_SIZE = 1024\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 1e-3\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUmKcKsF9cvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
        "\n",
        "task_specific_params = model.config.task_specific_params\n",
        "if task_specific_params is not None:\n",
        "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
        "    \n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=0.0001)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVyCw6HeCoqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "17d71b79-89a1-4b29-dcdb-2639deec011a"
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>cleaned_stories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
              "      <td>['Syrian official: Obama climbed to the top of...</td>\n",
              "      <td>it is official u.s. president barack obama wan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             article  ...                                    cleaned_stories\n",
              "0  It's official: U.S. President Barack Obama wan...  ...  it is official u.s. president barack obama wan...\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVFdbnTf9cvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SummaryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, articles, highlights):\n",
        "        self.x = articles\n",
        "        self.y = highlights\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = tokenizer.encode_plus(model.config.prefix + self.x[index], max_length=512,truncation=True ,return_tensors=\"pt\", pad_to_max_length=True)\n",
        "        y = tokenizer.encode(self.y[index], max_length=150, truncation=True,return_tensors=\"pt\", pad_to_max_length=True)\n",
        "        return x['input_ids'].view(-1), x['attention_mask'].view(-1), y.view(-1)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMKb3CJxCc4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdjhd-J29cvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train,df_test = train_test_split(df,test_size = 0.1)\n",
        "df_val ,df_test = train_test_split(df_test,test_size =0.5)\n",
        "\n",
        "train_dataset = SummaryDataset(articles = df_train.cleaned_stories.values, highlights = df_train.summary.values)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
        "\n",
        "val_dataset = SummaryDataset(articles = df_val.cleaned_stories.values, highlights = df_val.summary.values)\n",
        "val_data_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = SummaryDataset(articles = df_test.cleaned_stories.values, highlights = df_test.summary.values)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkOcLq4p9cvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_token_id = tokenizer.pad_token_id\n",
        "def step(inputs_ids, attention_mask, y):\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    lm_labels = y[:, 1:].clone()\n",
        "    lm_labels[y[:, 1:] == pad_token_id] = -100\n",
        "    output = model(inputs_ids, attention_mask=attention_mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
        "    return output[0] # loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlNvxQ_M9cv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43bcf4ae-10e3-44ab-f094-434530a3d13f"
      },
      "source": [
        "EPOCHS = 1\n",
        "log_interval = 2000\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train() \n",
        "    start_time = time.time()\n",
        "    for i, (inputs_ids, attention_mask, y) in enumerate(train_data_loader):\n",
        "        inputs_ids = inputs_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = step(inputs_ids, attention_mask, y)\n",
        "        train_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "            \n",
        "        if (i + 1) % log_interval == 0:\n",
        "            with torch.no_grad():\n",
        "                x, x_mask, y = next(iter(val_data_loader))\n",
        "                x = x.to(device)\n",
        "                x_mask = x_mask.to(device)\n",
        "                y = y.to(device)\n",
        "                \n",
        "                v_loss = step(x, x_mask, y)\n",
        "                v_loss = v_loss.item()\n",
        "                \n",
        "                \n",
        "                elapsed = time.time() - start_time\n",
        "                print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
        "                  'ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
        "                    epoch, i, len(train_data_loader),\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    loss.item(), v_loss))\n",
        "                start_time = time.time()\n",
        "                val_loss.append(v_loss)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   0 | [ 1999/ 5207] | ms/batch 793.36 | loss  3.44 | val loss  3.73\n",
            "| epoch   0 | [ 3999/ 5207] | ms/batch 793.65 | loss  3.59 | val loss  4.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwiB15oURX6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "097352a4-6d2c-424a-dd89-2271af609e5d"
      },
      "source": [
        "pip install rouge-score"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.18.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score) (0.10.0)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lsfHcG9cv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from rouge_score import scoring\n",
        "\n",
        "class RougeScore:\n",
        "    '''\n",
        "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
        "    '''\n",
        "    \n",
        "    def __init__(self, score_keys=None)-> None:\n",
        "        super().__init__()\n",
        "        if score_keys is None:  \n",
        "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
        "        \n",
        "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
        "        self.aggregator = scoring.BootstrapAggregator()\n",
        "        \n",
        "        \n",
        "    @staticmethod\n",
        "    def prepare_summary(summary):\n",
        "            # Make sure the summary is not bytes-type\n",
        "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
        "            summary = summary.replace(\" . \", \" .\\n\")\n",
        "            return summary\n",
        "    \n",
        "    def __call__(self, target, prediction):\n",
        "        \"\"\"Computes rouge score.''\n",
        "        Args:\n",
        "        targets: string\n",
        "        predictions: string\n",
        "        \"\"\"\n",
        "\n",
        "        target = self.prepare_summary(target)\n",
        "        prediction = self.prepare_summary(prediction)\n",
        "        \n",
        "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
        "\n",
        "        return \n",
        "    \n",
        "    def reset_states(self):\n",
        "        self.rouge_list = []\n",
        "\n",
        "    def result(self):\n",
        "        result = self.aggregator.aggregate()\n",
        "        \n",
        "        for key in self.score_keys:\n",
        "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
        "                key,\n",
        "                result[key].mid.fmeasure*100,\n",
        "                result[key].low.fmeasure*100,\n",
        "                result[key].high.fmeasure*100\n",
        "            )\n",
        "            print(score_text)\n",
        "        \n",
        "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ULEBjs9cv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "afbdc0be-a9d7-45cf-c712-5a0f16333e51"
      },
      "source": [
        "rouge_score = RougeScore()\n",
        "predictions = []\n",
        "for i, (input_ids, attention_mask, y) in enumerate(test_data_loader):\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    y = y.to(device)\n",
        "        \n",
        "    summaries = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
        "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
        "    for pred_sent, real_sent in zip(pred, real):\n",
        "        rouge_score(pred_sent, real_sent)\n",
        "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
        "    if i > 40:\n",
        "        break\n",
        "    \n",
        "rouge_score.result()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rouge1 = 21.03, 95% confidence [20.36, 21.65]\n",
            "rouge2 = 4.68, 95% confidence [4.29, 5.09]\n",
            "rougeLsum = 14.35, 95% confidence [13.88, 14.79]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 21.028184502046578,\n",
              " 'rouge2': 4.684724848699995,\n",
              " 'rougeLsum': 14.349246908595841}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NkoWnzW9cv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "8deefab3-4cbb-41d5-97db-df418af1397e"
      },
      "source": [
        "for pred in predictions[:10]:\n",
        "    print(\"------\")\n",
        "    print(pred)\n",
        "    print(\"------\")  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------\n",
            "pred sentence: ', 'She is a question of the midst of a mania induced rage', \"Michichichelle's mother is now a \"lelele\"]\n",
            "\n",
            " real sentence: ['Philip Lerman oversaw the missing child cases for \"America's Most Wanted\"', \"60 cases were solved but not the personal one: his stepsister's disappearance\", 'He saw brave families hold out hope, and show would air and re-air their cases', 'Lerman says every family of a missing child is holding onto hope after women found']\n",
            "------\n",
            "------\n",
            "pred sentence: ', 'The hefner says he will work to keep the puppy', \"The puppy's ring and the bentley\", 'His research for a bullet by not 100,000 life']\n",
            "\n",
            " real sentence: ['Hugh Hefner and Crystal Harris are fighting over their shared Cavalier King Charles spaniel', '\"We both love the puppy,\" Hefner said', '\"The puppy's valuable, but not $100,000 worth,\" he said']\n",
            "------\n",
            "------\n",
            "pred sentence: 'NEW: The death penalty has been dismissed for his facebook comment', 'The death death penalty is not in court', \"The breivik's death penalty's a CIA comment\"]\n",
            "\n",
            " real sentence: ['Keen: Breivik captures the delusional, violent, narcissistic nature of digital culture', 'Breivik killed 77 Norwegians in bomb and gun rampage in July 2011', 'Marche: Social networks like Facebook are making us lonely', 'Keen: Violent video games allowed Breivik to \"virtualize\" killing of real people']\n",
            "------\n",
            "------\n",
            "pred sentence: 'Two-inch tablet market has been announced', 'Apple fire is one of the same same resolution', \"Ipad's only only only the first generation generation generation\"]\n",
            "\n",
            " real sentence: [\"Apple's iPad Mini joins the 7-inch tablet market\", \"Amazon's Kindle Fire HD, Google's Nexus 7 are among current leaders\", \"Apple's display screen is bigger than the others, but $329 price tag is bigger, too\"]\n",
            "------\n",
            "------\n",
            "pred sentence: '', 'Senate Divergent answers to repeal repeal of a repeal', \"The law's allowing gays to serve openly divert\", 'The law should be repeals to repeal']\n",
            "\n",
            " real sentence: ['Sen. Scott Brown, R-Massachusetts, says he supports a repeal', 'McCain predicts that over 40 senators will oppose a bill repealing \"don't ask, don't tell\"', 'Different service leaders present different views on repeal', 'The head of the Marine Corps appeared most resistant to repealing the policy']\n",
            "------\n",
            "------\n",
            "pred sentence: 'Reporters will be forgotten', 'Britisyree made to set up the game', \"Michae's new York giants was one of the best football games\"]\n",
            "\n",
            " real sentence: [\"Ultimate Super Bowl party: Four kinds of pizza and a Giants' win\", '\"It's good to be in New York,\" reader says', \"One fan's daughter took first steps in second half\", 'I-Report: Have a story to share? Send it to us']\n",
            "------\n",
            "------\n",
            "pred sentence: 'NEW: \"We were keeping resistance\"', 'He says the church is a cut in the church of the church', \"NEW, he says's a ppp. see see scenes from the church\", 'His rewritten and crucifixion of the crucicrucicrucied']\n",
            "\n",
            " real sentence: ['Greek Orthodox and Armenian monks punch and kick each other', 'Police called to break up fight at Church of the Holy Sepulcher in Jerusalem', \"The site is believed to be where Jesus' crucifixion and resurrection occurred\"]\n",
            "------\n",
            "------\n",
            "pred sentence: '', 'Obama has pledges to make middle east peace', \"Israeli's aides say they're prepared to be a new president\", 'Israeli conflicted against Israel']\n",
            "\n",
            " real sentence: ['President-elect initiated eight-minute call with secretary of state', 'Obama \"will continue to closely monitor\" Middle East events, aide says', 'He has promised to make peace in the region a priority']\n",
            "------\n",
            "------\n",
            "pred sentence: 'NEW: Investigator says prosecutors says bulger', '\"We are up for the bill for 82822,000 in cash\"', \"The lawyer says he'll pay to pay for defense defense attorney\"]\n",
            "\n",
            " real sentence: [\"A judge appointed J.W. Carney Jr. as Bulger's public defender\", \"Bulger's arraignment is set for July 6\", 'A judge denied a petition to combine two pending racketeering cases', \"The judge ruled in favor of a prosecutor's request to dismiss a lesser indictment\"]\n",
            "------\n",
            "------\n",
            "pred sentence: 'NEW: \"I's not yet yet yet known\", he says', 'He has been confident confident the capital of the poorest nation', \"He says it's too early to give a number\"]\n",
            "\n",
            " real sentence: ['President Rene Preval says it is too early to know how many killed by quake', 'He says priority is to clear the streets so aid vehicles can get through', 'Preval says presidential mansion and his personal home are unlivable']\n",
            "------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnc5lJ1x9cwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/Colab Files/t5_summarization_model.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I9FWHwmRbBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}